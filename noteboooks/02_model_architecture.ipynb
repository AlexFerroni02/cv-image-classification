{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline CNN Architecture Design\n",
        "\n",
        "The purpose of this notebook is to design and implement a baseline\n",
        "Convolutional Neural Network (CNN) for the CIFAR-10 classification task.\n",
        "\n",
        "The goal is not to maximize accuracy, but to:\n",
        "- Build a clear and interpretable architecture\n",
        "- Understand the role of each component\n",
        "- Establish a strong and reliable baseline model\n"
      ],
      "metadata": {
        "id": "FwpimLw0MwEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Design Philosophy\n",
        "\n",
        "The baseline CNN follows these principles:\n",
        "\n",
        "- Simplicity over complexity\n",
        "- Gradual increase in representational capacity\n",
        "- Clear separation between feature extraction and classification\n",
        "- No reliance on pre-trained models\n",
        "\n",
        "This approach ensures that model behavior can be easily analyzed\n",
        "and debugged in later stages.\n"
      ],
      "metadata": {
        "id": "TZxU-iZKMxur"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hm2fXDV6Mm5u"
      },
      "outputs": [],
      "source": [
        "# Core PyTorch module for neural network components\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## High-Level Architecture\n",
        "\n",
        "The network is composed of two main parts:\n",
        "\n",
        "1. **Feature Extractor**\n",
        "   - A sequence of convolutional blocks\n",
        "   - Each block extracts increasingly abstract visual features\n",
        "\n",
        "2. **Classifier**\n",
        "   - Fully connected layers\n",
        "   - Maps extracted features to class probabilities\n",
        "\n",
        "The overall structure follows this pattern:\n",
        "\n",
        "Input → Conv Blocks → Flatten → Fully Connected Layers → Output\n"
      ],
      "metadata": {
        "id": "blLS0muINyjz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why Convolutional Layers?\n",
        "\n",
        "Convolutional layers are well-suited for image data because they:\n",
        "- Exploit spatial locality\n",
        "- Share parameters across the image\n",
        "- Are translation-equivariant\n",
        "\n",
        "These properties allow CNNs to learn meaningful visual features\n",
        "such as edges, textures, and object parts.\n"
      ],
      "metadata": {
        "id": "NVK6yWuwN21s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple convolutional neural network for CIFAR-10 classification.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # Feature extraction layers will be defined here\n",
        "        # Classification layers will be defined here\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass logic will be implemented here\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "wvPZ9LLMM1q7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Block Design\n",
        "\n",
        "Each convolutional block consists of:\n",
        "- Convolution\n",
        "- Non-linear activation (ReLU)\n",
        "- Spatial downsampling (MaxPooling)\n",
        "\n",
        "This pattern allows the network to:\n",
        "- Increase feature complexity\n",
        "- Reduce spatial resolution\n",
        "- Improve computational efficiency\n"
      ],
      "metadata": {
        "id": "13KCoO4KN-h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple convolutional neural network for CIFAR-10 classification.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # First convolutional block\n",
        "        # Input: 3 x 32 x 32\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "\n",
        "        # Second convolutional block\n",
        "        # Input: 32 x 16 x 16\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "\n",
        "        # Third convolutional block\n",
        "        # Input: 64 x 8 x 8\n",
        "        self.conv_block3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n"
      ],
      "metadata": {
        "id": "_xLa8wMaM2Hb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Map Size Progression\n",
        "\n",
        "The spatial resolution evolves as follows:\n",
        "\n",
        "- Input: 32 x 32\n",
        "- After Block 1: 16 x 16\n",
        "- After Block 2: 8 x 8\n",
        "- After Block 3: 4 x 4\n",
        "\n",
        "At the same time, the number of channels increases:\n",
        "- 3 → 32 → 64 → 128\n",
        "\n",
        "This reflects a common CNN design strategy:\n",
        "reduce spatial dimensions while increasing feature richness.\n"
      ],
      "metadata": {
        "id": "cpOHwv-JOIhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why Max Pooling?\n",
        "\n",
        "Max pooling is used to:\n",
        "- Reduce spatial resolution\n",
        "- Introduce local translation invariance\n",
        "- Lower computational cost\n",
        "\n",
        "While more advanced alternatives exist, max pooling provides\n",
        "a strong and interpretable baseline.\n"
      ],
      "metadata": {
        "id": "0TwBBTKHOLVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple convolutional neural network for CIFAR-10 classification.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # Feature extraction\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.conv_block3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        # Classification head\n",
        "        # After conv blocks, feature map size is 128 x 4 x 4\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n"
      ],
      "metadata": {
        "id": "4hWCh-jPPDLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fully Connected Layers\n",
        "\n",
        "The classifier maps high-level visual features to class scores.\n",
        "\n",
        "A hidden layer with ReLU activation is used to:\n",
        "- Introduce additional non-linearity\n",
        "- Allow the model to learn complex decision boundaries\n"
      ],
      "metadata": {
        "id": "or1Esn5hPFIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple convolutional neural network for CIFAR-10 classification.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.conv_block3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract spatial features\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.conv_block3(x)\n",
        "\n",
        "        # Flatten feature maps into a vector\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Classification layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "V08gd1YVPHY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Summary and Expectations\n",
        "\n",
        "This baseline CNN:\n",
        "- Contains a small number of parameters\n",
        "- Is easy to train and debug\n",
        "- Provides a strong reference point for future improvements\n",
        "\n",
        "Expected performance:\n",
        "- Significantly better than random guessing (10%)\n",
        "- Not state-of-the-art, but reliable and interpretable\n",
        "\n",
        "This model will serve as the foundation for training, evaluation,\n",
        "and subsequent architectural enhancements.\n"
      ],
      "metadata": {
        "id": "atKqdHckPJmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Steps\n",
        "\n",
        "The next stage of the project will focus on:\n",
        "- Implementing the training pipeline\n",
        "- Defining loss functions and optimizers\n",
        "- Evaluating model performance on the test set\n"
      ],
      "metadata": {
        "id": "IUnP40H2PM2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2DdIo73qPSrd"
      }
    }
  ]
}